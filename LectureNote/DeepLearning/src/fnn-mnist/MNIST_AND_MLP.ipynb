{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5862b76",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-03T07:15:59.820423Z",
     "iopub.status.busy": "2025-09-03T07:15:59.820147Z",
     "iopub.status.idle": "2025-09-03T07:16:01.242614Z",
     "shell.execute_reply": "2025-09-03T07:16:01.241800Z"
    },
    "papermill": {
     "duration": 1.427498,
     "end_time": "2025-09-03T07:16:01.243971",
     "exception": false,
     "start_time": "2025-09-03T07:15:59.816473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mnist-and-mlp-2/MNIST/processed/training.pt\n",
      "/kaggle/input/mnist-and-mlp-2/MNIST/processed/test.pt\n",
      "/kaggle/input/mnist-and-mlp-2/MNIST/raw/t10k-labels-idx1-ubyte/t10k-labels.idx1-ubyte\n",
      "/kaggle/input/mnist-and-mlp-2/MNIST/raw/t10k-images-idx3-ubyte/t10k-images.idx3-ubyte\n",
      "/kaggle/input/mnist-and-mlp-2/MNIST/raw/train-labels-idx1-ubyte/train-labels.idx1-ubyte\n",
      "/kaggle/input/mnist-and-mlp-2/MNIST/raw/train-images-idx3-ubyte/train-images.idx3-ubyte\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df263644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T07:16:01.249985Z",
     "iopub.status.busy": "2025-09-03T07:16:01.249384Z",
     "iopub.status.idle": "2025-09-03T07:16:10.754878Z",
     "shell.execute_reply": "2025-09-03T07:16:10.754200Z"
    },
    "papermill": {
     "duration": 9.509865,
     "end_time": "2025-09-03T07:16:10.756381",
     "exception": false,
     "start_time": "2025-09-03T07:16:01.246516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "class MNISTDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    MNIST数据集加载器\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y):\n",
    "        self._x = x\n",
    "        self._y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"images\": torch.tensor(self._x[idx], dtype=torch.float32),\n",
    "            \"label\": torch.tensor(self._y[idx], dtype=torch.long),\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._x)\n",
    "\n",
    "# 定义数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # MNIST是灰度图像，只有一个通道\n",
    "])\n",
    "\n",
    "def prepare_data_loader(\n",
    "    ratio: float,\n",
    "    train_batch_size: int,\n",
    "    num_workers: int,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    参数:\n",
    "        path (str): .npz格式的数据集文件路径\n",
    "        ratio (float): 训练集比例\n",
    "        train_batch_size (int): 批次大小\n",
    "        num_workers (int): 数据加载的工作进程数\n",
    "    返回:\n",
    "        dict: 包含训练和测试数据加载器的字典\n",
    "    \"\"\"\n",
    "    print(\"开始加载数据...\")  # 添加调试信息\n",
    "    train_dataset = datasets.MNIST(root='/kaggle/input/mnist-and-mlp-2/', train=True,  transform=transform)\n",
    "    test_dataset = datasets.MNIST(root='/kaggle/input/mnist-and-mlp-2/', train=False,  transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "                                                dataset=train_dataset, \n",
    "                                               batch_size=train_batch_size, \n",
    "                                               shuffle=True,\n",
    "                                               drop_last=True,\n",
    "                                               pin_memory=True  \n",
    "                                              )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "                                              dataset=test_dataset, \n",
    "                                              batch_size=train_batch_size, \n",
    "                                              shuffle=False,\n",
    "                                               drop_last=False,\n",
    "                                               pin_memory=True  \n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"数据加载器创建完成\")  # 添加调试信息\n",
    "\n",
    "    return {\"train\": train_loader, \"test\": test_loader}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40e5e17b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T07:16:10.762478Z",
     "iopub.status.busy": "2025-09-03T07:16:10.761397Z",
     "iopub.status.idle": "2025-09-03T07:16:10.769256Z",
     "shell.execute_reply": "2025-09-03T07:16:10.768600Z"
    },
    "papermill": {
     "duration": 0.011645,
     "end_time": "2025-09-03T07:16:10.770318",
     "exception": false,
     "start_time": "2025-09-03T07:16:10.758673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    可配置的多层感知机模型\n",
    "    \n",
    "    参数:\n",
    "        input_size (int): 输入特征维度 (对于MNIST是1*28*28=784)\n",
    "        num_classes (int): 分类类别数\n",
    "        hidden_layers (list): 每个隐藏层的输出维度列表\n",
    "        dropout_rate (float): Dropout比率\n",
    "        activation (str): 激活函数类型 ('relu', 'tanh', 'sigmoid')\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int = 784,  \n",
    "        num_classes: int = 10,\n",
    "        hidden_layers: list = [512, 256, 128],  # 默认三层隐藏层\n",
    "        dropout_rate: float = 0.1,\n",
    "        activation: str = 'relu'\n",
    "    ):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        \n",
    "        # 选择激活函数\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation}\")\n",
    "            \n",
    "        # 构建隐藏层\n",
    "        self.fc_blocks = nn.ModuleList()\n",
    "        current_dim = input_size\n",
    "        \n",
    "        for hidden_dim in hidden_layers:\n",
    "            print(f\"Adding FC block with input dim {current_dim} and output dim {hidden_dim}\")\n",
    "            fc_block = nn.Sequential(\n",
    "                nn.Linear(current_dim, hidden_dim),\n",
    "                self.activation,\n",
    "                nn.BatchNorm1d(hidden_dim),  # 添加批归一化\n",
    "                nn.Dropout(dropout_rate)\n",
    "            )\n",
    "            self.fc_blocks.append(fc_block)\n",
    "            current_dim = hidden_dim\n",
    "            \n",
    "        # 输出层\n",
    "        self.output_layer = nn.Linear(current_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 展平输入\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1)\n",
    "        \n",
    "        # 通过所有隐藏层\n",
    "        for fc_block in self.fc_blocks:\n",
    "            x = fc_block(x)\n",
    "            \n",
    "        # 输出层\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b169dcdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T07:16:10.775443Z",
     "iopub.status.busy": "2025-09-03T07:16:10.775243Z",
     "iopub.status.idle": "2025-09-03T07:16:10.789377Z",
     "shell.execute_reply": "2025-09-03T07:16:10.788833Z"
    },
    "papermill": {
     "duration": 0.018115,
     "end_time": "2025-09-03T07:16:10.790458",
     "exception": false,
     "start_time": "2025-09-03T07:16:10.772343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_step(\n",
    "    model: nn.Module, optimizer, batch: dict, device: torch.device\n",
    "):\n",
    "    \"\"\"\n",
    "    单步训练\n",
    "    \"\"\"\n",
    "    batch_images, labels = batch\n",
    "    batch_images = batch_images.to(device)\n",
    "    labels = labels.to(device)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    logits = model(batch_images) # 模型正向过程\n",
    "        \n",
    "    loss = loss_fn(logits, labels) # 计算总损失\n",
    "        \n",
    "    loss.backward() # 反向传播\n",
    "        \n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # 添加梯度裁剪，防止梯度爆炸\n",
    "        \n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), logits, labels\n",
    "        \n",
    "\n",
    "def eval_step(model: nn.Module, batch: dict, device: torch.device):\n",
    "    # 单步评估\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch_images, labels = batch\n",
    "        batch_images = batch_images.to(device)\n",
    "        labels = labels.to(device) \n",
    "        logits = model(batch_images) # 模型正向过程\n",
    "        loss = loss_fn(logits, labels) # 计算总损失\n",
    "        return loss.item(), logits, labels\n",
    "    \n",
    "def train_per_epoch(\n",
    "    model: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    batch_size: int,\n",
    "    train_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "):\n",
    "    model.train()\n",
    "    num_data = len(train_loader.dataset)\n",
    "    num_batches = len(train_loader)\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    print(f\"开始训练 - 总样本数: {num_data}\")\n",
    "    print(f\"总批次数: {len(train_loader)}\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        loss, logits, labels = train_step(model, optimizer, batch, device)\n",
    "        total_loss += loss\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        correct += (predicted == labels).sum().item()    \n",
    "        if batch_idx % 50 == 0:  # 改为每50个批次打印一次\n",
    "            current = batch_idx * batch_size + len(batch[0])\n",
    "            print(f\"批次 {batch_idx}: Loss: {loss:>6.4f}, 进度: {current:>5d}/{num_data:>5d}\")\n",
    "    accuracy = correct / num_data\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Train Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {avg_loss:>.8f} \\n\")\n",
    "        \n",
    "def test_per_epoch(\n",
    "    model: nn.Module,\n",
    "    test_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "):\n",
    "    \"\"\"\n",
    "    每轮测试\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    num_batches = len(test_loader)\n",
    "    num_data = len(test_loader.dataset)\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            loss, logits, labels = eval_step(model, batch, device)\n",
    "            total_loss += loss\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    accuracy = correct / num_data\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {avg_loss:>.8f} \\n\")\n",
    "    return 100*accuracy\n",
    "\n",
    "\n",
    "def controller(\n",
    "    seed: int,\n",
    "    # MLP特有参数\n",
    "    input_size: int = None,\n",
    "    hidden_layers: list = None,\n",
    "    activation: str = 'relu',\n",
    "    \n",
    "    # 通用参数\n",
    "    num_classes: int = 10,\n",
    "    dropout_rate: float = 0.1,\n",
    "    ratio: float = 0.8,\n",
    "    train_batch_size: int = 64,\n",
    "    num_workers: int = 4,\n",
    "    epochs: int = 10,\n",
    "    learning_rate: float = 0.001,\n",
    "    weight_decay: float = 0.004\n",
    "):\n",
    "    \"\"\"\n",
    "    训练控制器\n",
    "    \n",
    "    参数:\n",
    "        model_type: 选择模型类型 ('MLP' 或 'mlp')\n",
    "        其他参数见各模型的文档\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    model = SimpleMLP(\n",
    "            input_size=input_size,\n",
    "            num_classes=num_classes,\n",
    "            hidden_layers=hidden_layers,\n",
    "            dropout_rate=dropout_rate,\n",
    "            activation=activation\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)  #选择Adam优化器\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=epochs) # 选择余弦退火模型\n",
    "    loader_dict = prepare_data_loader(ratio=ratio, train_batch_size=train_batch_size, num_workers=2 )\n",
    "    train_loader = loader_dict[\"train\"]\n",
    "    test_loader = loader_dict[\"test\"]\n",
    "    print(f\"Using device: {device}\") \n",
    "    best_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1} \\n--------------------------------\")\n",
    "        train_per_epoch(model, optimizer, train_batch_size, train_loader, device)\n",
    "        acc = test_per_epoch(model, test_loader, device)\n",
    "        scheduler.step()\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "    print(f\"Training completed! Best accuracy: {best_acc:.2f}%\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1506e48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T07:16:10.795206Z",
     "iopub.status.busy": "2025-09-03T07:16:10.794969Z",
     "iopub.status.idle": "2025-09-03T07:16:24.864135Z",
     "shell.execute_reply": "2025-09-03T07:16:24.863245Z"
    },
    "papermill": {
     "duration": 14.073,
     "end_time": "2025-09-03T07:16:24.865418",
     "exception": false,
     "start_time": "2025-09-03T07:16:10.792418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding FC block with input dim 784 and output dim 512\n",
      "Adding FC block with input dim 512 and output dim 256\n",
      "Adding FC block with input dim 256 and output dim 128\n",
      "开始加载数据...\n",
      "数据加载器创建完成\n",
      "Using device: cuda\n",
      "Epoch 1 \n",
      "--------------------------------\n",
      "开始训练 - 总样本数: 60000\n",
      "总批次数: 468\n",
      "批次 0: Loss: 2.4645, 进度:   128/60000\n",
      "批次 50: Loss: 0.2616, 进度:  6528/60000\n",
      "批次 100: Loss: 0.3786, 进度: 12928/60000\n",
      "批次 150: Loss: 0.2635, 进度: 19328/60000\n",
      "批次 200: Loss: 0.2619, 进度: 25728/60000\n",
      "批次 250: Loss: 0.1751, 进度: 32128/60000\n",
      "批次 300: Loss: 0.2186, 进度: 38528/60000\n",
      "批次 350: Loss: 0.1025, 进度: 44928/60000\n",
      "批次 400: Loss: 0.1186, 进度: 51328/60000\n",
      "批次 450: Loss: 0.1513, 进度: 57728/60000\n",
      "Train Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.26609505 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.14513153 \n",
      "\n",
      "Training completed! Best accuracy: 95.45%\n"
     ]
    }
   ],
   "source": [
    "# 随机数种子：确保每次运行代码得到相同的结果\n",
    "seed = 42\n",
    "\n",
    "# 全连接层配置：定义MLP末端全连接层的结构\n",
    "# [128, 64]表示有两层全连接层，第一层有128个神经元，第二层有64个神经元\n",
    "hidden_layers = [512, 256, 128]\n",
    "\n",
    "# Dropout比率：随机\"关闭\"一部分神经元，防止模型过度依赖某些特征\n",
    "# 比率0.2表示每次训练时随机关闭20%的神经元\n",
    "dropout_rate = 0.2\n",
    "\n",
    "#ratio比率：训练集中用于训练的数据量/总数据量\n",
    "#比率0.8表示50000张图片中有40000张用于训练，10000用于测试\n",
    "ratio = 0.8\n",
    "\n",
    "# 训练轮数：整个训练数据集要被训练的次数\n",
    "epochs = 1\n",
    "\n",
    "# 批次大小：每次训练选取的图片数量\n",
    "batch_size = 128\n",
    "\n",
    "# 学习率：模型在训练过程中调整参数的步长\n",
    "learning_rate = 0.001\n",
    "\n",
    "#  MLP模型示例\n",
    "model = controller(\n",
    "    seed=seed,\n",
    "    input_size=1*28*28,  # MNIST数据集的输入大小\n",
    "    hidden_layers = hidden_layers,\n",
    "    dropout_rate=dropout_rate,\n",
    "    ratio = ratio,\n",
    "    epochs=epochs,  \n",
    "    train_batch_size=batch_size,  \n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay = 0.004 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e76b722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T07:16:24.871447Z",
     "iopub.status.busy": "2025-09-03T07:16:24.871230Z",
     "iopub.status.idle": "2025-09-03T07:16:26.640572Z",
     "shell.execute_reply": "2025-09-03T07:16:26.639913Z"
    },
    "papermill": {
     "duration": 1.773554,
     "end_time": "2025-09-03T07:16:26.641677",
     "exception": false,
     "start_time": "2025-09-03T07:16:24.868123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始加载数据...\n",
      "数据加载器创建完成\n",
      "测试集准确率: 0.9545\n",
      "预测结果已保存至 /kaggle/working/submission.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9545"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def evaluater_with_dataloader_and_save(model, test_loader, device, solution_path=None):\n",
    "    \"\"\"\n",
    "    使用 test_dataloader 计算准确率并可选择保存预测结果\n",
    "    \n",
    "    参数:\n",
    "    - model: 需要评估的模型\n",
    "    - test_loader: 测试数据加载器\n",
    "    - device: 计算设备 (CPU 或 GPU)\n",
    "    - solution_path: 保存预测结果的路径(可选)\n",
    "    \n",
    "    返回:\n",
    "    - accuracy: 模型在测试集上的准确率\n",
    "    \"\"\"\n",
    "    model.eval()  # 设置为评估模式\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_ids = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():  # 不计算梯度\n",
    "        for images, labels in test_loader:\n",
    "            # 如果 test_loader 包含ID信息，需要相应调整这里的解包方式\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # 如果需要保存预测结果\n",
    "            if solution_path is not None:\n",
    "                # 假设我们能够获取ID信息\n",
    "                batch_ids = range(len(all_predictions), len(all_predictions) + len(predicted))\n",
    "                all_ids.extend(batch_ids)\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f'测试集准确率: {accuracy:.4f}')\n",
    "    \n",
    "    # 保存预测结果\n",
    "    if solution_path is not None:\n",
    "        predictions_df = pd.DataFrame({\"ID\": all_ids, \"label\": all_predictions})\n",
    "        predictions_df.to_csv(solution_path, index=False)\n",
    "        print(f'预测结果已保存至 {solution_path}')\n",
    "    \n",
    "    return accuracy\n",
    "loader_dict = prepare_data_loader(train_batch_size=128, num_workers=2,ratio=0.8 )\n",
    "train_loader = loader_dict[\"train\"]\n",
    "test_loader = loader_dict[\"test\"]\n",
    "evaluater_with_dataloader_and_save(\n",
    "    model,\n",
    "    test_loader=test_loader,\n",
    "    solution_path=Path(\"/kaggle/working/submission.csv\"),\n",
    "    device = device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba36980",
   "metadata": {
    "papermill": {
     "duration": 0.002526,
     "end_time": "2025-09-03T07:16:26.646999",
     "exception": false,
     "start_time": "2025-09-03T07:16:26.644473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13604480,
     "sourceId": 114085,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33.230539,
   "end_time": "2025-09-03T07:16:28.937160",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-03T07:15:55.706621",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
