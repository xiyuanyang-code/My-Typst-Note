{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7C0480D97F344544BC2824225ADBF12D",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 策略梯度算法\n",
    "\n",
    "本次作业包含2个代码填空和3个Exercise。\n",
    "\n",
    "# 简介\n",
    "之前我们介绍的Q-learning和DQN及改进算法都是基于价值（value-based）的方法，其中Q-learning是处理有限状态的算法，而DQN可以用来解决连续状态的问题。在强化学习中，除了基于值函数的方法，还有一支非常经典的方法，那就是基于策略（policy-based）的方法。对比两者，基于值函数的方法主要是学习值函数，然后根据值函数导出一个策略，此时并不存在一个显式的策略；而基于策略的方法则是直接显式的学习一个目标策略。策略梯度是基于策略的方法的基础，我们将从策略梯度算法说起。\n",
    "# 策略梯度\n",
    "基于策略的方法首先需要参数化策略，我们假设目标策略$\\pi_\\theta$是一个随机性策略，并且处处可微，其中$\\theta$是对应的参数。我们的目标是要寻找一个最优策略，来最大化这个策略在环境中的期望回报。我们将策略学习的目标函数定义为\n",
    "$$\n",
    "J(\\theta)= \\mathbb{E}_{s_0}\\left[V^{\\pi_\\theta}(s_0)\\right]\n",
    "$$\n",
    "其中$s_0$表示初始状态。现在有了目标函数，我们将目标函数对策略$\\theta$求导，得到导数后，我们就可以用梯度上升方法来最大化这个目标函数从而得到最优策略。\n",
    "\n",
    "我们之前在MDP章节中学习过在策略$\\pi$下的状态访问分布，我们在此用$\\nu^{\\pi}$表示。然后我们对目标函数求梯度，可以得到如下式子，更详细的推导将在扩展阅读中给出。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\nabla_{\\theta}J(\\theta)\n",
    "&\\propto \\sum_{s \\in S}\\nu^{\\pi_{\\theta}}(s)\\sum_{a \\in A}Q^{\\pi_{\\theta}}(s,a)\\nabla_{\\theta}\\pi_{\\theta}(a|s)\\\\\n",
    "&=\\sum_{s \\in S}\\nu^{\\pi_{\\theta}}(s)\\sum_{a \\in A}\\pi_{\\theta}(a|s)Q^{\\pi_{\\theta}}(s,a)\\frac{\\nabla_{\\theta}\\pi_{\\theta}(a|s)}{\\pi_{\\theta}(a|s)}\\\\\n",
    "&= \\mathbb{E}_{\\pi_{\\theta}}[Q^{\\pi_{\\theta}}(s,a)\\nabla_{\\theta}\\log \\pi_{\\theta}(a|s)]\n",
    "\\end{align}\n",
    "$$\n",
    "于是，我们就可以用这个梯度来更新策略。需要注意的是，因为上式期望$\\mathbb{E}$的下标是$\\pi_{\\theta}$，所以策略梯度算法为在线策略（on-policy）算法，即必须使用当前策略$\\pi_\\theta$采样得到的数据来计算梯度。更一般地，我们可以把梯度写成下面这个形式：\n",
    "$$\n",
    "g = \\mathbb{E}_{\\pi_{\\theta}}[\\sum^{\\infty}_{t=0}\\psi_{t}\\nabla_{\\theta}\\log \\pi_{\\theta}(a_{t}|s_{t})]\n",
    "$$\n",
    "其中$\\psi_{t}$可以有很多种形式：\n",
    "$$\n",
    "\\begin{align}\n",
    "&1.\\psi_{t}=\\sum_{t=0}^{\\infty}\\gamma^t r_{t} : 轨迹的总回报  &&4.Q^{\\pi_{\\theta}}(s_{t},a_{t}) : 动作价值函数\\\\\n",
    "&2.\\psi_{t}=\\sum_{t'=t}^{\\infty} \\gamma^{t'-t} r_{t'} : 动作 a_{t}之后的回报 &&5.A^{\\pi_{\\theta}}(s_{t},a_{t}): 优势函数\\\\\n",
    "&3.\\psi_{t}=\\sum_{t'=t}^{\\infty}r_{t'}-b(s_{t}) : 基准线版本的改进 \\quad\\quad \\quad\\quad &&6.r_{t} + V^{\\pi_{\\theta}}(s_{t+1}) - V^{\\pi_{\\theta}}(s_t) : 时序差分残差\n",
    "\\end{align}\n",
    "$$\n",
    "在计算策略梯度的公式中，我们需要用到$Q^{\\pi_{\\theta}}(s,a)$，可以用多种方式对它进行估计。接下来要介绍的 REINFORCE 算法便是采用了蒙特卡洛方法来估计$Q^{\\pi_{\\theta}}(s,a)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.** 请简单阐述策略梯度方法与基于值函数的方法有何区别。\n",
    "\n",
    "- 基于值函数的方法：\n",
    "   - 关键在于学习拟合值函数 $V(s)$ 和 $Q(s,a)$\n",
    "   - 在拟合价值函数之后根据贪婪策略选择当前方法来最大化收益：$a^* = \\arg \\max_{a \\in A} Q(s,a)$\n",
    "   - 值函数往往在连续的动作空间中难以处理\n",
    "- 策略梯度方法：\n",
    "   - 直接学习智能体策略 $\\pi_\\theta (a|s)$，输出每个状态下采取各个动作的概率分布\n",
    "   - 策略梯度天然适合处理连续动作空间，可以输出连续动作的概率分布\n",
    "   - 可能会陷入收敛到局部最优解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCE 算法\n",
    "REINFORCE就是在上文中当$\\psi_t=\\sum_{t'=t}^{\\infty}\\gamma^{t'-t}r_{t'}$时的策略梯度算法。\n",
    "具体流程如下：\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\cdot 初始化策略参数\\theta \\\\\n",
    "&\\cdot \\texttt{for}\\quad 序列\\quad e=1\\to E\\quad \\texttt{do}: \\\\\n",
    "&\\cdot\\qquad 用当前策略\\pi_\\theta采样轨迹\\{s_{1},a_{1},r_{1},s_{2},a_{2},r_{2} ... s_{t},a_{t},r_{t}\\}\\\\\n",
    "&\\cdot\\qquad 计算当前轨迹每个时刻t往后的回报\\sum_{t'=t}^{\\infty}\\gamma^{t'-t}r_{t'}，记为\\psi_{t}\\\\\n",
    "&\\cdot\\qquad 对\\theta进行更新 \\theta = \\theta + \\alpha \\sum_{t=0}^{\\infty}\\psi_{t}\\nabla_{\\theta}\\log \\pi_{\\theta}(a_{t}|s_{t})\\\\\n",
    "&\\cdot\\texttt{end for}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2F59DF8812534F36874771F8720C93B7",
    "jupyter": {},
    "notebookId": "5f8f327c46ba5e00307827a4",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -i https://mirrors.sjtug.sjtu.edu.cn/pypi/web/simple gym\n",
    "%pip install torch # No need to install cuda toolkit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "40B616B26E8B4AA48E98B4258C7988CA",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "eps = np.finfo(np.float32).eps.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7C0E3A3A844549BC905ED109D604EF92",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "定义我们的策略网络PolicyNet，输入是状态state，输出则是采取动作action的概率值（离散动作空间）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "864658B0470F4AB4823322580ED41CDA",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PolicyNet(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, state_space, action_space):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        input_dim = state_space.shape[0]\n",
    "        output_dim = action_space.n\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return  F.softmax(self.fc2(x), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6A19E6CFCEDC467BA350D1200C7E28B6",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "再定义我们的REINFORCE的Agent。在函数action()中，我们通过概率对离散的动作进行采样。在更新Agent的过程中，我们按照算法，将损失函数写为$-\\sum_{t}\\psi_{t}\\nabla_{\\theta}\\log \\pi_{\\theta}(a_{t}|s_{t})$，对$\\theta$求导就可以更新策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "677551348C8D4AAE8AE44C4B46AEFA26",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Reinforce:\n",
    "    def __init__(\n",
    "        self, \n",
    "        hidden_size, state_space, action_space, \n",
    "        learning_rate, device, step_size, lr_gamma\n",
    "    ):\n",
    "        self.action_space = action_space\n",
    "        self.model = PolicyNet(hidden_size, state_space, action_space).to(device)\n",
    "        self.device = device\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size, lr_gamma)\n",
    "\n",
    "    def action(self, state):\n",
    "        ########################################\n",
    "        ## Programming 1: 计算正确的action以及log_prob\n",
    "        ########################################\n",
    "        state_tensor = torch.FloatTensor(state).to(self.device) if not isinstance(state, torch.Tensor) else state\n",
    "        action_probs = self.model(state_tensor)\n",
    "        dist = Categorical(action_probs)\n",
    "        action = dist.sample()\n",
    "        log_prob = dist.log_prob(action)\n",
    "        ########################################\n",
    "        ## End of Programming 1\n",
    "        ########################################\n",
    "        return action, log_prob\n",
    "\n",
    "    def update(self, rewards, log_probs, gamma):\n",
    "        ########################################\n",
    "        ## Programming 2: 更新策略网络\n",
    "        ## REINFORCE算法通常不太稳定，如果得到的结果不理想可以尝试：\n",
    "        ## 1. 对**Return**做标准化\n",
    "        ## 2. 使用learning rate调节器\n",
    "        ########################################\n",
    "        \n",
    "        # 计算折扣回报\n",
    "        R = 0\n",
    "        returns = []\n",
    "        for r in rewards[::-1]:\n",
    "            R = r + gamma * R\n",
    "            returns.insert(0, R)\n",
    "        \n",
    "        returns = torch.tensor(returns, dtype=torch.float32).to(self.device)\n",
    "        \n",
    "        # 标准化回报以减少方差\n",
    "        returns = (returns - returns.mean()) / (returns.std() + eps)\n",
    "        \n",
    "        # 计算损失函数\n",
    "        loss = []\n",
    "        for log_prob, R in zip(log_probs, returns):\n",
    "            loss.append(-log_prob * R)\n",
    "        \n",
    "        loss = torch.stack(loss).sum()\n",
    "        \n",
    "        # 反向传播更新参数\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step()\n",
    "        \n",
    "        ########################################\n",
    "        ## End of Programming 2\n",
    "        ########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6DDA156DE31493CA22217FA65E3C43E",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "定义好策略，我们就可以开始实验了，看看Reinforce在Cartpole环境上表现如何吧！\n",
    "\n",
    "预计运行时间：2分钟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "A9993AF344AE4770896E0504E77BAF08",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2b/h_bq65kn6yl2fnz8tsk_2hvw0000gn/T/ipykernel_99971/469349111.py:34: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/distiller/project/pytorch/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  state = torch.Tensor([next_state], device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100, Reward: 34.6\n",
      "Episode: 200, Reward: 76.3\n",
      "Episode: 300, Reward: 184.9\n",
      "Episode: 400, Reward: 320.2\n",
      "Episode: 500, Reward: 414.8\n",
      "Episode: 600, Reward: 427.2\n",
      "Episode: 700, Reward: 428.6\n",
      "Episode: 800, Reward: 500.0\n",
      "Episode: 900, Reward: 444.8\n",
      "Episode: 1000, Reward: 480.4\n",
      "Episode: 1100, Reward: 474.3\n",
      "Episode: 1200, Reward: 480.7\n",
      "Episode: 1300, Reward: 500.0\n",
      "Episode: 1400, Reward: 500.0\n",
      "Episode: 1500, Reward: 489.0\n",
      "Episode: 1600, Reward: 500.0\n",
      "Episode: 1700, Reward: 500.0\n",
      "Episode: 1800, Reward: 490.0\n",
      "Episode: 1900, Reward: 500.0\n",
      "Episode: 2000, Reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "# 以下参数在助教实现的版本中能达到期望效果，可以多试几组参数\n",
    "learning_rate = 1e-3\n",
    "num_episode = 2000\n",
    "hidden_size = 128\n",
    "max_timesteps = 2000\n",
    "env_name = \"CartPole-v1\"\n",
    "gamma = 0.98\n",
    "lr_gamma = 0.9\n",
    "step_size = 500\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "env = gym.make(env_name)\n",
    "agent = Reinforce(\n",
    "    hidden_size, \n",
    "    env.observation_space, \n",
    "    env.action_space, \n",
    "    learning_rate, \n",
    "    device,\n",
    "    step_size,\n",
    "    lr_gamma\n",
    ")\n",
    "rewards_log = []\n",
    "episodes_log = []\n",
    "for i_episode in range(num_episode):\n",
    "    state = torch.Tensor(np.array([env.reset()]), device=device)\n",
    "    log_probs = []\n",
    "    rewards = []\n",
    "    for time_step in range(max_timesteps):\n",
    "        action, log_prob = agent.action(state)\n",
    "        action = action.cpu()\n",
    "        next_state, reward, terminated, truncated = env.step(action.numpy()[0])\n",
    "        done = terminated or truncated\n",
    "        log_probs.append(log_prob)\n",
    "        rewards.append(reward)\n",
    "        state = torch.Tensor([next_state], device=device)\n",
    "        if done:\n",
    "            break\n",
    "    rewards_log.append(np.sum(rewards))\n",
    "    episodes_log.append(i_episode)\n",
    "    agent.update(rewards, log_probs, gamma)\n",
    "    if (i_episode + 1) % 100 == 0 or i_episode + 1 == num_episode:\n",
    "        print(\"Episode: {}, Reward: {}\".format(i_episode+1, np.mean(rewards_log[-10:])))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CB975960A51D4D97A708F800DAEB03EE",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "在CartPole-v1环境中，满分就是500分，让我们来看看每个Episode得分如何吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "D2B1AD392B66419791F4FD6CB800A4A9",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episodes_log,rewards_log)\n",
    "plt.xlabel('Episodes')   \n",
    "plt.ylabel('Rewards per episode')  \n",
    "plt.title('Reinforce on {}'.format(env_name))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8CF05803C4D491FB9A8684DEC5BF217",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "6073bce2d143c8001737e6a4",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "参考训练曲线如下（最后能比较稳定保持在500即可）：\n",
    "\n",
    "![Image Name](images/result.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.** 在填写代码并训练的过程，你认为REINFORCE算法存在哪些问题？\n",
    "\n",
    "- 高方差问题：REINFORCE使用蒙特卡洛方法估计回报，单次轨迹的采样方差很大，相同的状态-动作对在不同轨迹中可能得到完全不同的回报估计、高方差导致训练不稳定，收敛速度慢\n",
    "   - 后续引入优势函数 $A(s,a) = Q(s,a) - V(s)$ 以及 TD Learning 来代替全回合的 Monte Carlo 更新。\n",
    "   - 上述措施均可以降低累积汇报 $G_t$ 的方差\n",
    "\n",
    "- 样本效率低下：\n",
    "   - REINFORCE 算法为 on-policy 算法，需要从环境中实时收集数据进行训练。\n",
    "   - 后续加入 Importance Sampling (PPO & TRPO) 来保证模型能够利用旧策略的轨迹数据来更新当前的策略\n",
    "   - 深度离散策略梯度的方法通过离线经验回放池，让历史数据可以被反复训练\n",
    "\n",
    "- 学习率 $\\alpha$ 敏感难以控制：\n",
    "   - 策略梯度对学习率极其敏感。在 REINFORCE 中，一次权重更新可能导致概率分布发生剧烈跳变。如果某次随机采样运气很差，梯度可能会把策略推向一个“崩溃区”，导致模型后续再也无法探索到有效路径。\n",
    "   - 后续 TRPO 算法引入 KL 散度的正则约束，强制要求新旧策略的分布差异不能超过一个阈值\n",
    "   - 后续 PPO 算法引入 CLIP 裁剪机制，限制损失函数的更新幅度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7BF78B87D294A038E9BEA15C75E8940",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 总结\n",
    "REINFORCE算法理论上是能保证局部最优的。依赖于MC方法进行采样，优点是REINFORCE的采样梯度是无偏的。但是同样由于MC，导致REINFORCE梯度估计的方差很大，从而可能会降低学习的速率，这也是接下来的Actor-Critic算法要解决的问题。\n",
    "\n",
    "# 拓展阅读：策略梯度证明\n",
    "我们要证明$\\nabla_{\\theta}J(\\theta) \\propto \\sum_{s \\in S}\\nu^{\\pi_\\theta}(s)\\sum_{a \\in A}Q^{\\pi_\\theta}(s,a)\\nabla_{\\theta}\\pi_{\\theta}(a|s)$\n",
    "                        \n",
    "先从状态价值函数的推导开始：\n",
    "$$\n",
    "\\begin{align}\n",
    "\\nabla_{\\theta}V^{\\pi_\\theta}(s) &=\\nabla_{\\theta}(\\sum_{a \\in A} \\pi_{\\theta}(a|s)Q^{\\pi_\\theta}(s,a)) \\\\\n",
    "&=\\sum_{a\\in A}(\\nabla_{\\theta}\\pi_{\\theta}(a|s)Q^{\\pi_\\theta}(s,a) + \\pi_{\\theta}(a|s)\\nabla_{\\theta}Q^{\\pi_\\theta}(s,a))\\\\\n",
    "&=\\sum_{a\\in A}(\\nabla_{\\theta}\\pi_{\\theta}(a|s)Q^{\\pi_\\theta}(s,a) + \\pi_{\\theta}(a|s)\\nabla_{\\theta}\\sum_{s',r}P(s',r|s,a)(r+\\gamma V^{\\pi_\\theta}(s'))\\\\\n",
    "&=\\sum_{a\\in A}(\\nabla_{\\theta}\\pi_{\\theta}(a|s)Q^{\\pi_\\theta}(s,a) + \\gamma\\pi_{\\theta}(a|s)\\sum_{s',r}P(s',r|s,a)\\nabla_{\\theta}V^{\\pi_\\theta}(s'))\\\\\n",
    "&=\\sum_{a\\in A}(\\nabla_{\\theta}\\pi_{\\theta}(a|s)Q^{\\pi_\\theta}(s,a) + \\gamma\\pi_{\\theta}(a|s)\\sum_{s'}P(s'|s,a)\\nabla_{\\theta}V^{\\pi_\\theta}(s'))\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "为了简化表示，我们让$\\phi(s)=\\sum_{a \\in A}\\nabla_{\\theta}\\pi_{\\theta}(a|s)Q^{\\pi_\\theta}(s,a)$, 定义$\\rho^{\\pi}(s\\rightarrow x, k)$为策略$\\pi$从状态s出发k步后到达状态x的概率，我们继续推导:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\nabla_{\\theta}V^{\\pi_\\theta}(s) &= \\phi(s) + \\gamma\\sum_{a}\\pi_{\\theta}(a|s)\\sum_{s'}P(s'|s,a)\\nabla_{\\theta}V^{\\pi_\\theta}(s')\\\\\n",
    "&= \\phi(s) + \\gamma\\sum_{a}\\sum_{s'}\\pi_{\\theta}(a|s)P(s'|s,a)\\nabla_{\\theta}V^{\\pi_\\theta}(s')\\\\\n",
    "&= \\phi(s) + \\gamma\\sum_{s'}\\rho^{\\pi_\\theta}(s \\rightarrow s',1)\\nabla_{\\theta}V^{\\pi_\\theta}(s')\\\\\n",
    "&= \\phi(s) + \\gamma\\sum_{s'}\\rho^{\\pi_\\theta}(s \\rightarrow s',1)[\\phi(s') + \\sum_{s''}\\rho^{\\pi_\\theta}(s' \\rightarrow s'',1)\\nabla_{\\theta}V^{\\pi_\\theta}(s'')]\\\\\n",
    "&= \\phi(s) + \\gamma\\sum_{s'}\\rho^{\\pi_\\theta}(s \\rightarrow s',1)\\phi(s') + \\sum_{s''}\\rho^{\\pi_\\theta}(s \\rightarrow s'',2)\\nabla_{\\theta}V^{\\pi_\\theta}(s'')\\\\\n",
    "&= \\phi(s) + \\gamma\\sum_{s'}\\rho^{\\pi_\\theta}(s \\rightarrow s',1)\\phi(s') +\\gamma^2\\sum_{s''}\\rho^{\\pi_\\theta}(s' \\rightarrow s'',2)\\phi(s'') + \\gamma^3\\sum_{s'''}\\rho^{\\pi_\\theta}(s \\rightarrow s''',3)\\nabla_{\\theta}V^{\\pi_\\theta}(s''')\\\\\n",
    "&= ......\\\\\n",
    "&= \\sum_{x \\in S}\\sum^{\\infty}_{k=0}\\gamma^k\\rho^{\\pi_\\theta}(s \\rightarrow x, k)\\phi(x)\n",
    "\\end{align}\n",
    "$$\n",
    "OK! 我们定义$\\eta(s)= \\mathbb{E}_{s_0}\\left[\\sum^{\\infty}_{k=0}\\gamma^k\\rho^{\\pi}(s_{0} \\rightarrow s, k)\\right]$。\n",
    "至此我们看回我们的目标函数：\n",
    "$$\n",
    "\\begin{align}\n",
    "\\nabla_{\\theta}J(\\theta) &= \\nabla_{\\theta}\\mathbb{E}_{s_0}\\left[V^{\\pi_\\theta}(s_{0})\\right]\\\\\n",
    "&= \\sum_{s}\\mathbb{E}_{s_0}\\left[\\sum^{\\infty}_{k=0}\\gamma^k\\rho^{\\pi_\\theta}(s_{0} \\rightarrow s, k)\\right]\\phi(s)\\\\\n",
    "&= \\sum_{s}\\eta(s)\\phi(s)\\\\\n",
    "&= \\left(\\sum_{s}\\eta(s)\\right)\\sum_{s}\\frac{\\eta(s)}{\\sum_{s}\\eta(s)}\\phi(s)\\\\\n",
    "&\\propto \\sum_{s}\\frac{\\eta(s)}{\\sum_{s}\\eta(s)}\\phi(s)\\\\\n",
    "&= \\sum_{s}\\nu^{\\pi_\\theta}(s)\\sum_{a}Q^{\\pi_\\theta}(s,a)\\nabla_{\\theta}\\pi_{\\theta}(a|s)\n",
    "\\end{align}\n",
    "$$\n",
    "证明完毕！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Exercise 3.** 以优势函数$A(s_t,a_t)$为例，请说明为什么沿着梯度$g$的方向优化就可以学到一个收益更大的策略。\n",
    "\n",
    "**答案：**\n",
    "\n",
    "优势函数$A(s_t,a_t) = Q(s_t,a_t) - V(s_t)$表示在状态$s_t$下采取动作$a_t$相对于平均水平的优势程度。沿着梯度\n",
    "\n",
    "$$g = \\mathbb{E}_{\\pi_{\\theta}}[A^{\\pi_{\\theta}}(s_{t},a_{t})\\nabla_{\\theta}\\log \\pi_{\\theta}(a_{t}|s_{t})]$$\n",
    "\n",
    "的方向优化，可以学习到收益更大的策略。\n",
    "\n",
    "梯度公式可以分解为两个关键部分：\n",
    "- $A(s_t,a_t)$：衡量动作$a_t$的优劣程度\n",
    "- $\\nabla_{\\theta}\\log \\pi_{\\theta}(a_{t}|s_{t})$：指示如何调整参数来增加该动作的概率\n",
    "\n",
    "- 如果 $A(s_t,a_t) > 0$（考虑做标准化，即代表动作优于平均水平），此时梯度的方向和 $\\nabla_{\\theta}\\log \\pi_{\\theta}(a_{t}|s_{t})$ 保持相同。沿着梯度的方向更新策略可以保证价值函数处在上升更快的方向，可以学到一个收益更大的策略。具体而言，更新后的 $\\theta$ 会增加这个好动作出现的概率。\n",
    "- 如果 $A(s_t,a_t) < 0$，同理，参数更新会减小此类坏动作的出现概率。\n",
    "\n",
    "经过多次迭代，策略的概率分布会逐渐向那些高分动作区域收敛，最终学到最优策略。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
